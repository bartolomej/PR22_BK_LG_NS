{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Status based classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "objects_raw = pd.read_csv(\"../data/objects.csv\", sep=\",\", low_memory=False)\n",
    "objects = objects_raw.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's define some helper functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class RowIterator(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Prepare dataframe for DictVectorizer\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (row for _, row in X.iterrows())\n",
    "\n",
    "\n",
    "class FillingNans(object):\n",
    "    \"\"\"\n",
    "    Custom function for assembling into the pipeline object\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, X):\n",
    "        nans_replaced = X.fillna(0)\n",
    "        return nans_replaced\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartolomejkozorog/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# exclude companies with operating status\n",
    "# this status is pretty useless, because it doesn't tell much about how successful this company is\n",
    "# operating status just tells us that company is still existing, which is a pretty neutral fact\n",
    "objects = objects[objects[\"status\"] != 'operating']\n",
    "\n",
    "# build text features with dictionary vectorizer method\n",
    "vectX = make_pipeline(FillingNans(), RowIterator(), DictVectorizer())\n",
    "dict_vect_features = vectX.fit_transform(objects.filter(['entity_type', 'category_code', 'country_code', 'state_code']))\n",
    "\n",
    "# build text features with TfId vectorizer method\n",
    "objects_text = objects.filter(['description', 'short_description'])\n",
    "texts = [' '.join(map(lambda x: '' if str(x) == 'nan' else x, value)).strip() for value in objects_text.values]\n",
    "tdif_vect = TfidfVectorizer()\n",
    "tfid_vect_features = tdif_vect.fit_transform(texts)\n",
    "pd.DataFrame(tfid_vect_features.toarray(), columns=tdif_vect.get_feature_names())\n",
    "\n",
    "# combine separate feature matrices into a single matrix\n",
    "X = hstack((dict_vect_features, tfid_vect_features))\n",
    "\n",
    "# build expected vector\n",
    "y = LabelEncoder().fit_transform(objects.filter(['status']))\n",
    "\n",
    "# now lets split the\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split the data into testing and training sets\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0, train_size=0.7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def evaluate_data(train=X1, test=X2):\n",
    "    evaluate_model(DummyClassifier(strategy='most_frequent'), train, test, \"Dummy\")\n",
    "    evaluate_model(SVC(kernel='linear'), train, test, \"SVM\")\n",
    "\n",
    "\n",
    "def evaluate_model(model, train, test, label):\n",
    "    model.fit(train, y1)\n",
    "    y2_model = model.predict(test)\n",
    "    print(f\"{label}: \", accuracy_score(y2, y2_model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model evaluation\n",
    "\n",
    "Let's first evaluate the data without any transormations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy:  0.4860452869931543\n",
      "SVM:  0.7303844128488678\n"
     ]
    }
   ],
   "source": [
    "evaluate_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's use SVD method for dimensionality reduction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy:  0.4860452869931543\n",
      "SVM:  0.7187993680884676\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "proj_X1 = svd.fit_transform(X1)\n",
    "proj_X2 = svd.fit_transform(X2)\n",
    "evaluate_data(train=proj_X1, test=proj_X2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the explained variance curve with respect to the number of components for SVD."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "projected = svd.fit_transform(X)\n",
    "plt.plot(np.cumsum(svd.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}